{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/jiangxiaoyu/Desktop/All Projects/GPLVM_project_code/')\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "from linear_operator.operators import KroneckerProductLinearOperator\n",
    "from torch import Tensor\n",
    "from torch.distributions import MultivariateNormal\n",
    "from models_.lvmogp_svi import LVMOGP_SVI\n",
    "from models_.gaussian_likelihood import GaussianLikelihood\n",
    "from models_.variational_elbo import VariationalELBO\n",
    "from tqdm import trange\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from util_functions import *\n",
    "import yaml\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experi random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expri_random_seed =  12  # 13, 78, 912, 73, 269"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double Check this with data folder title! Make sure import the correct one.\n",
    "w_n_C_total = 50 # totally 700 points for C\n",
    "w_n_outputs = 5000 # 100, 300, 500, 1000, 2500(20), 1500, 2000\n",
    "\n",
    "synth_data_path = f'/Users/jiangxiaoyu/Desktop/All Projects/GPLVM_project_code/data/synth_regression/smartly_generated/ninputs_{w_n_C_total}_nlatents_{w_n_outputs}'\n",
    "w_C_total = Tensor(pd.read_csv(f'{synth_data_path}/inputs.csv').to_numpy()).reshape(-1)\n",
    "w_X_true = Tensor(pd.read_csv(f'{synth_data_path}/latents.csv').to_numpy()).reshape(-1, 2)\n",
    "w_sample_total_data = Tensor(pd.read_csv(f'{synth_data_path}/target_data.csv').to_numpy()).reshape(-1)\n",
    "\n",
    "w_n_C_train = 25 # the number of training data points per output\n",
    "w_n_C_test = w_n_C_total - w_n_C_train\n",
    "\n",
    "np.random.seed(expri_random_seed)\n",
    "torch.manual_seed(expri_random_seed)\n",
    "list_expri_random_seeds = np.random.randn(w_n_outputs)\n",
    "\n",
    "# different from the previous case, C_train and C_test no longer a single set, but every output has different values.\n",
    "w_ls_of_ls_train_C = []\n",
    "w_ls_of_ls_test_C = []\n",
    "\n",
    "w_sample_train_index, w_sample_test_index = [], []\n",
    "\n",
    "for i in range(w_n_outputs):\n",
    "    # iterate across different output functions\n",
    "    random.seed(list_expri_random_seeds[i])\n",
    "    train_index = random.sample(range(w_n_C_total), w_n_C_train)\n",
    "    test_index = [index for index in range(w_n_C_total) if index not in train_index]\n",
    "    w_ls_of_ls_train_C.append(train_index)\n",
    "    w_ls_of_ls_test_C.append(test_index)\n",
    "\n",
    "    w_sample_train_index = np.concatenate((w_sample_train_index, list(np.array(train_index) + w_n_C_total*i)))\n",
    "    w_sample_test_index = np.concatenate((w_sample_test_index, list(np.array(test_index) + w_n_C_total*i)))\n",
    "\n",
    "w_sample_train_data = w_sample_total_data[w_sample_train_index]\n",
    "w_sample_test_data = w_sample_total_data[w_sample_test_index]\n",
    "\n",
    "assert w_sample_train_data.shape[0] == w_n_C_train * w_n_outputs\n",
    "assert w_sample_test_data.shape[0] == w_n_C_test * w_n_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_train_variational_params_fix_others(true_hyperparams, my_model, my_likelihood):\n",
    "    \n",
    "    # assign true values to model hyper-parameters\n",
    "    my_model.covar_module_latent.raw_outputscale.data = torch.tensor(true_hyperparams['X_raw_outputscale'])\n",
    "    my_model.covar_module_input.raw_outputscale.data = torch.tensor(true_hyperparams['C_raw_outputscale'])\n",
    "    my_model.covar_module_latent.base_kernel.raw_lengthscale.data = torch.tensor([true_hyperparams['X_raw_lengthscale']])\n",
    "    my_model.covar_module_input.base_kernel.raw_lengthscale.data = torch.tensor([true_hyperparams['C_raw_lengthscale']])\n",
    "    my_likelihood.noise = torch.tensor(true_hyperparams['likelihood_noise']) # NOTE: not .data !\n",
    "\n",
    "    # fix gradient updates for hyperparameters\n",
    "    my_model.covar_module_latent.raw_outputscale.requires_grad = False\n",
    "    my_model.covar_module_input.raw_outputscale.requires_grad = False\n",
    "    my_model.covar_module_latent.base_kernel.raw_lengthscale.requires_grad = False\n",
    "    my_model.covar_module_input.base_kernel.raw_lengthscale.requires_grad = False\n",
    "    my_likelihood.raw_noise.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper-parameters\n",
    "w_n_X = w_X_true.shape[0]\n",
    "w_n_C = len(w_ls_of_ls_train_C[0])\n",
    "w_n_total = w_n_X * w_n_C\n",
    "w_index_dim = 1\n",
    "w_latent_dim = 2\n",
    "w_n_inducing_C = 30\n",
    "w_n_inducing_X = 30\n",
    "w_pca = False\n",
    "learn_inducing_locations_X= True # True\n",
    "learn_inducing_locations_C = True\n",
    "\n",
    "Y_train = w_sample_train_data\n",
    "\n",
    "# specify model\n",
    "w_my_model = LVMOGP_SVI(w_n_X, w_n_C, w_index_dim, w_latent_dim, w_n_inducing_C, w_n_inducing_X, Y_train.reshape(w_n_X, -1), pca=w_pca, learn_inducing_locations_latent=learn_inducing_locations_X, learn_inducing_locations_input=learn_inducing_locations_C)\n",
    "\n",
    "# Likelihood & training objective\n",
    "w_likelihood = GaussianLikelihood()\n",
    "w_mll = VariationalELBO(w_likelihood, w_my_model, num_data=w_n_total)\n",
    "\n",
    "import json\n",
    "with open(f'{synth_data_path}/dictionary.json', 'r') as file:\n",
    "    true_hyperparams = json.load(file)\n",
    "true_hyperparams['likelihood_noise'] = 0.05\n",
    "\n",
    "# only_train_variational_params_fix_others(true_hyperparams=true_hyperparams, my_model=w_my_model, my_likelihood=w_likelihood)\n",
    "\n",
    "# optimizer and scheduler\n",
    "w_optimizer = torch.optim.Adam([\n",
    "    {'params': w_my_model.parameters()},\n",
    "    {'params': w_likelihood.parameters()}\n",
    "], lr=0.1)\n",
    "\n",
    "w_scheduler = StepLR(w_optimizer, step_size=20, gamma=0.95)  # every 50 iterations, learning rate multiple 0.95\n",
    "\n",
    "# Initialize inducing points in C space\n",
    "w_my_model.variational_strategy.inducing_points_input.data = Tensor(np.linspace(-10, 10, w_n_inducing_C).reshape(-1, 1))\n",
    "# Another initialization: random initialization\n",
    "# i.e. torch.rand(w_n_inducing_C).reshape(-1,1) * 20 - 10\n",
    "\n",
    "# Initialize inducing points in latent space\n",
    "# w_my_model.variational_strategy.inducing_points_X.data = 3 * torch.randn(w_n_inducing_X, w_latent_dim)\n",
    "\n",
    "# Initialize likelihood noise as true value, 0.05\n",
    "w_likelihood.raw_noise.data = Tensor([-2.973])\n",
    "# w_likelihood.raw_noise.requires_grad = False\n",
    "\n",
    "# start training!\n",
    "w_loss_list = []\n",
    "n_iterations = 1000 # 5000 # 10000\n",
    "iterator = trange(n_iterations, leave=True)\n",
    "batch_size_X = 50 # mini-batch for latents\n",
    "batch_size_C = 20 # mini-batch for inputs, one can set w_n_C_train\n",
    "num_X_MC = 5 # the number of MC samples used to approximate E_{q(X)}\n",
    "w_model_max_grad_norm = 1\n",
    "w_likeli_max_grad_norm = 0.1\n",
    "\n",
    "'''\n",
    "for name, params in w_my_model.named_parameters():\n",
    "    print(name)\n",
    "for name, params in w_likelihood.named_parameters():\n",
    "    print(name)\n",
    "'''\n",
    "\n",
    "w_my_model.train()\n",
    "w_likelihood.train()\n",
    "start_time = time.time()\n",
    "for i in iterator: \n",
    "    batch_index_X, batch_index_C = sample_index_X_and_C_from_list(w_ls_of_ls_train_C, batch_size_X=batch_size_X, batch_size_C=batch_size_C)\n",
    "    # core code is here \n",
    "    w_optimizer.zero_grad()\n",
    "\n",
    "    loss_value = 0.0\n",
    "    for _ in range(num_X_MC):\n",
    "        sample_batch_X = w_my_model.sample_latent_variable(batch_index_X)\n",
    "        sample_batch_C = w_C_total[batch_index_C]\n",
    "        output_batch = w_my_model(sample_batch_X, sample_batch_C) # q(f)\n",
    "        batch_index_Y = inhomogeneous_index_of_batch_Y(batch_index_X, batch_index_C, w_n_X, w_n_C_total)\n",
    "        # print('batch_index_Y', len(batch_index_Y))\n",
    "        loss = -w_mll(output_batch, w_sample_total_data[batch_index_Y]).sum()\n",
    "        loss_value += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "    loss_value /= num_X_MC\n",
    "    \n",
    "    w_loss_list.append(loss_value)\n",
    "    iterator.set_description('Loss: ' + str(float(np.round(loss_value, 3))) + \", iter no: \" + str(i))\n",
    "    \n",
    "    # Clip gradients\n",
    "    torch.nn.utils.clip_grad_norm_(w_my_model.parameters(), w_model_max_grad_norm)\n",
    "    torch.nn.utils.clip_grad_norm_(w_likelihood.parameters(), w_likeli_max_grad_norm)\n",
    "\n",
    "    w_optimizer.step()\n",
    "    w_scheduler.step()\n",
    "    \n",
    "end_time = time.time()\n",
    "print('Total Training Time:',  end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove abnormal values (happens when non psd matrix cholesky occur)\n",
    "w_loss_list = list(np.array(w_loss_list)[np.array(w_loss_list) < 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(w_loss_list)\n",
    "train_loss_path = f'/Users/jiangxiaoyu/Desktop/All Projects/GPLVM_project_code/experi_results/syn_data_training_loss_numofoutput_{w_n_outputs}.png'\n",
    "plt.savefig(train_loss_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction output for grid (total) inputs.\n",
    "w_my_model.eval()\n",
    "w_likelihood.eval()\n",
    "\n",
    "all_index_X = np.array([[i]*w_n_C_total for i in range(w_n_outputs)]).reshape(-1).tolist() \n",
    "all_index_C = [i for i in range(w_n_C_total)] * w_n_outputs \n",
    "len_X = len(all_index_X)\n",
    "assert len_X == len(all_index_C)\n",
    "all_mean_X = w_my_model.X.q_mu\n",
    "\n",
    "test_mini_batch_size = 1000\n",
    "\n",
    "all_pred_mean = torch.zeros(len_X)\n",
    "all_pred_var = torch.zeros(len_X)\n",
    "test_continue = True\n",
    "test_start_idx = 0\n",
    "test_end_idx = test_mini_batch_size\n",
    "\n",
    "while test_continue:\n",
    "    batch_X = all_mean_X[all_index_X[test_start_idx:test_end_idx]]\n",
    "    batch_C = w_C_total[all_index_C[test_start_idx:test_end_idx]]\n",
    "    batch_output = w_likelihood(w_my_model(batch_X, batch_C))\n",
    "    all_pred_mean[test_start_idx:test_end_idx] = batch_output.loc.detach()\n",
    "    all_pred_var[test_start_idx:test_end_idx] = batch_output.variance.detach()\n",
    "\n",
    "    if test_end_idx < len_X:\n",
    "        test_start_idx += test_mini_batch_size\n",
    "        test_end_idx += test_mini_batch_size\n",
    "        test_end_idx = min(test_end_idx, len_X)\n",
    "    else:\n",
    "        test_continue = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finer grid for better visualization ... nothing to do with RMSE computation ... \n",
    "\n",
    "n_data4visual = 500\n",
    "w_C_total4visual = Tensor(np.linspace(-10, 10, n_data4visual))\n",
    "all_index_X4visual = np.array([[i]*n_data4visual for i in range(w_n_outputs)]).reshape(-1).tolist() \n",
    "all_index_C4visual = [i for i in range(n_data4visual)] * w_n_outputs \n",
    "\n",
    "len_X4visual = len(all_index_X4visual)\n",
    "assert len_X4visual == len(all_index_C4visual)\n",
    "\n",
    "test_mini_batch_size = 1000\n",
    "\n",
    "all_pred_mean4visual = torch.zeros(len_X4visual)\n",
    "all_pred_var4visual = torch.zeros(len_X4visual)\n",
    "\n",
    "test_continue = True\n",
    "test_start_idx = 0\n",
    "test_end_idx = test_mini_batch_size\n",
    "\n",
    "while test_continue:\n",
    "    batch_X = all_mean_X[all_index_X4visual[test_start_idx:test_end_idx]]\n",
    "    batch_C = w_C_total4visual[all_index_C4visual[test_start_idx:test_end_idx]]\n",
    "    batch_output = w_likelihood(w_my_model(batch_X, batch_C))\n",
    "    all_pred_mean4visual[test_start_idx:test_end_idx] = batch_output.loc.detach()\n",
    "    all_pred_var4visual[test_start_idx:test_end_idx] = batch_output.variance.detach()\n",
    "\n",
    "    if test_end_idx < len_X4visual:\n",
    "        test_start_idx += test_mini_batch_size\n",
    "        test_end_idx += test_mini_batch_size\n",
    "        test_end_idx = min(test_end_idx, len_X4visual)\n",
    "    else:\n",
    "        test_continue = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test data RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train_data_predict = all_pred_mean[w_sample_train_index]\n",
    "train_rmse = (w_train_data_predict - w_sample_train_data).square().mean().sqrt()\n",
    "print('Global Train RMSE', train_rmse)\n",
    "\n",
    "w_test_data_predict = all_pred_mean[w_sample_test_index]\n",
    "test_rmse = (w_test_data_predict - w_sample_test_data).square().mean().sqrt()\n",
    "print('Global Test RMSE', test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test data NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nll = neg_log_likelihood(Target=w_sample_train_data, GaussianMean=all_pred_mean[w_sample_train_index], GaussianVar=all_pred_var[w_sample_train_index])\n",
    "test_nll = neg_log_likelihood(Target=w_sample_test_data, GaussianMean=all_pred_mean[w_sample_test_index], GaussianVar=all_pred_var[w_sample_test_index])\n",
    "\n",
    "print('Global Train negative log likelihood:', train_nll)\n",
    "print('Global Test negative log likelihood', test_nll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_simgle_output(w_function_index):\n",
    "    # Pick the index of the funtion to show\n",
    "    # w_function_index = 982 # \n",
    "\n",
    "    performance_dirct = {}\n",
    "    w_train_input = w_C_total[w_ls_of_ls_train_C[w_function_index]]\n",
    "    w_train_start = 0\n",
    "    for i in range(w_function_index):\n",
    "        w_train_start += len(w_ls_of_ls_train_C[i]) # don't assume every output has the same length of inputs\n",
    "    w_train_end = w_train_start + len(w_ls_of_ls_train_C[w_function_index])\n",
    "    w_train_target = w_sample_train_data[w_train_start:w_train_end]\n",
    "    w_train_predict = w_train_data_predict[w_train_start:w_train_end]\n",
    "    train_rmse_ = (w_train_target - w_train_predict).square().mean().sqrt()\n",
    "    train_nll_ = neg_log_likelihood(w_train_target, all_pred_mean[w_sample_train_index][w_train_start:w_train_end], all_pred_var[w_sample_train_index][w_train_start:w_train_end])\n",
    "    performance_dirct['train_rmse'] = train_rmse_\n",
    "    performance_dirct['train_nll'] = train_nll_\n",
    "\n",
    "    w_test_input = w_C_total[w_ls_of_ls_test_C[w_function_index]]\n",
    "    w_test_start = 0\n",
    "    for j in range(w_function_index):\n",
    "        w_test_start += len(w_ls_of_ls_test_C[i])\n",
    "    w_test_end = w_test_start + len(w_ls_of_ls_test_C[w_function_index])\n",
    "    w_test_target = w_sample_test_data[w_test_start:w_test_end]\n",
    "    w_test_predict = w_test_data_predict[w_test_start:w_test_end]\n",
    "    test_rmse_ = (w_test_predict - w_test_target).square().mean().sqrt()\n",
    "    test_nll_ = neg_log_likelihood(w_test_target, all_pred_mean[w_sample_test_index][w_test_start:w_test_end], all_pred_var[w_sample_test_index][w_test_start:w_test_end])\n",
    "    performance_dirct['test_rmse'] = test_rmse_\n",
    "    performance_dirct['test_nll'] = test_nll_\n",
    "\n",
    "    w_gp_input = w_C_total\n",
    "    w_gp_start = w_gp_input.shape[0] * w_function_index\n",
    "    w_gp_end = w_gp_start + w_gp_input.shape[0]\n",
    "    w_gp_target = w_sample_total_data[w_gp_start:w_gp_end]\n",
    "\n",
    "    # NOTE: comment these since bad visualization ... \n",
    "    # w_gp_pred_mean = all_pred_mean[w_gp_start:w_gp_end]\n",
    "    # w_gp_pred_std = all_pred_var[w_gp_start:w_gp_end]\n",
    "\n",
    "    w_gp4visual_start = n_data4visual * w_function_index\n",
    "    w_gp4visual_end = n_data4visual * (w_function_index + 1)\n",
    "    w_gp_pred_mean = all_pred_mean4visual[w_gp4visual_start:w_gp4visual_end]\n",
    "    w_gp_pred_std = all_pred_var4visual.sqrt()[w_gp4visual_start:w_gp4visual_end]\n",
    "\n",
    "    return w_train_input, w_train_target, w_test_input, w_test_target, w_gp_pred_mean, w_gp_pred_std, performance_dirct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function_index = 22\n",
    "# w_train_input, w_train_target, w_test_input, w_test_target, w_gp_pred_mean, w_gp_pred_std, performance_dirct = evaluate_on_simgle_output(function_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(performance_dirct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picture_save_path = f'/Users/jiangxiaoyu/Desktop/All Projects/GPLVM_project_code/experi_results/func_id_{function_index}_numofoutput_{w_n_outputs}.png'\n",
    "# plot_traindata_testdata_fittedgp(train_X=w_train_input, train_Y=w_train_target, test_X=w_test_input, test_Y=w_test_target, gp_X=w_C_total4visual, gp_pred_mean=w_gp_pred_mean, gp_pred_std=w_gp_pred_std, inducing_points_X=w_my_model.variational_strategy.inducing_points_C.data, n_inducing_C=w_n_inducing_C, picture_save_path=picture_save_path) # NOTE: input is C not X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loop over all function index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_list = [] # list of tensors\n",
    "test_rmse_list = []\n",
    "train_nll_list = []\n",
    "test_nll_list = []\n",
    "for output_index in range(w_n_outputs):\n",
    "    _, _, _, _, _, _, performance_dirct = evaluate_on_simgle_output(output_index)\n",
    "    train_rmse_list.append(performance_dirct['train_rmse'])\n",
    "    test_rmse_list.append(performance_dirct['test_rmse'])\n",
    "    train_nll_list.append(performance_dirct['train_nll'])\n",
    "    test_nll_list.append(performance_dirct['test_nll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_median_index(lst):\n",
    "    sorted_lst = sorted(lst)\n",
    "    n = len(lst)\n",
    "    \n",
    "    if n % 2 != 0:\n",
    "        median = sorted_lst[n // 2]\n",
    "        return lst.index(median)\n",
    "    else:\n",
    "        mid1 = sorted_lst[n // 2 - 1]\n",
    "        mid2 = sorted_lst[n // 2]\n",
    "        \n",
    "        return lst.index(mid1)  # lst.index(mid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The output index with WORSE test rmse performance: ', test_rmse_list.index(max(test_rmse_list)))\n",
    "print('The output index with WORSE test nll performance: ', test_nll_list.index(max(test_nll_list)))\n",
    "print('------' * 10)\n",
    "print('The output index with MIDDLE test rmse performance:', find_median_index(test_rmse_list))\n",
    "print('The output index with MIDDLE test nll performance:', find_median_index(test_nll_list))\n",
    "print('------' * 10)\n",
    "print('The output index with BEST test rmse performance: ', test_rmse_list.index(min(test_rmse_list)))\n",
    "print('The output index with BEST test nll performance: ', test_nll_list.index(min(test_nll_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_index = 375\n",
    "w_train_input, w_train_target, w_test_input, w_test_target, w_gp_pred_mean, w_gp_pred_std, performance_dirct = evaluate_on_simgle_output(function_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_save_path = f'/Users/jiangxiaoyu/Desktop/All Projects/GPLVM_project_code/experi_results/func_id_{function_index}_numofoutput_{w_n_outputs}.png'\n",
    "plot_traindata_testdata_fittedgp(train_X=w_train_input, train_Y=w_train_target, test_X=w_test_input, test_Y=w_test_target, gp_X=w_C_total4visual, gp_pred_mean=w_gp_pred_mean, gp_pred_std=w_gp_pred_std, inducing_points_X=w_my_model.variational_strategy.inducing_points_input.data, n_inducing_C=w_n_inducing_C, picture_save_path=picture_save_path) # NOTE: input is C not X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check hyper-parameters after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f'{synth_data_path}/dictionary.json', 'r') as file:\n",
    "    true_kernel_data = json.load(file)\n",
    "print(true_kernel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w_my_model.covar_module_latent.outputscale.detach())\n",
    "print(w_my_model.covar_module_latent.base_kernel.lengthscale.detach())\n",
    "print(w_my_model.covar_module_input.outputscale.detach())\n",
    "print(w_my_model.covar_module_input.base_kernel.lengthscale.detach())\n",
    "# print(w_likelihood.raw_noise.detach())\n",
    "print(w_likelihood.noise.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True v.s. Fitted Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert w_my_model.X.q_mu.detach().shape == w_X_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_cov_matrix = w_my_model.covar_module_X(w_my_model.X.q_mu.detach()).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted_covar_module_X = ScaleKernel(RBFKernel(ard_num_dims=w_X_true.shape[1]))\n",
    "# fitted_covar_module_X.raw_outputscale.data = Tensor([true_kernel_data['X_raw_outputscale']])\n",
    "# fitted_covar_module_X.base_kernel.raw_lengthscale.data = Tensor([true_kernel_data['X_raw_lengthscale']])\n",
    "# fitted_cov_matrix = fitted_covar_module_X(w_X_true).to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True v.s. Fitted latent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_true_and_fitted_latent(w_X_true, w_my_model.X.q_mu.detach(), torch.nn.functional.softplus(w_my_model.X.q_log_sigma.detach()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(w_my_model.state_dict(), '/Users/jiangxiaoyu/Desktop/All Projects/GPLVM_project_code/experi_results/model_weight.pth')\n",
    "# torch.save(w_likelihood.state_dict(), '/Users/jiangxiaoyu/Desktop/All Projects/GPLVM_project_code/experi_results/likelihood_weight.pth')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPLVM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
