{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/jiangxiaoyu/Desktop/All Projects/GPLVM_project_code/')\n",
    "import yaml\n",
    "import torch\n",
    "# from models_.lvmogp_svi import LVMOGP_SVI\n",
    "from modules.prepare_and_train_model import LVMOGP_SVI \n",
    "from models_.gaussian_likelihood import GaussianLikelihood\n",
    "from modules.prepare_data import *\n",
    "from util_functions import *\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model and likelihood\n",
    "\n",
    "with open('/Users/jiangxiaoyu/Desktop/All Projects/GPLVM_project_code/configs/spatiotemp_lvmogp_config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "my_model = LVMOGP_SVI(\n",
    "    n_outputs = config['n_outputs'],\n",
    "    n_input = config['n_input_train'],\n",
    "    input_dim = config['input_dim'],\n",
    "    latent_dim = config['latent_dim'],\n",
    "    n_inducing_input = config['n_inducing_input'],\n",
    "    n_inducing_latent = config['n_inducing_latent'],\n",
    "    data_Y = None,\n",
    "    pca = config['pca'],\n",
    "    learn_inducing_locations_latent = config['learn_inducing_locations_latent'],\n",
    "    learn_inducing_locations_input = config['learn_inducing_locations_input'],\n",
    "    latent_kernel_type = config['latent_kernel_type'],\n",
    "    input_kernel_type = config['input_kernel_type']\n",
    ")\n",
    "\n",
    "my_likelihood = GaussianLikelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LVMOGP_SVI:\n\tsize mismatch for covar_module_input.kernels.1.base_kernel.raw_lengthscale: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([1, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load trained model and likelihood\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model_state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_model_path\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_state_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m likelihood_state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_likelihood_path\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m my_likelihood\u001b[38;5;241m.\u001b[39mload_state_dict(likelihood_state_dict)\n",
      "File \u001b[0;32m~/anaconda3/envs/GPLVM/lib/python3.9/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LVMOGP_SVI:\n\tsize mismatch for covar_module_input.kernels.1.base_kernel.raw_lengthscale: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([1, 1])."
     ]
    }
   ],
   "source": [
    "# Load trained model and likelihood\n",
    "\n",
    "model_state_dict = torch.load(config['min_model_path'])\n",
    "my_model.load_state_dict(model_state_dict)\n",
    "\n",
    "likelihood_state_dict = torch.load(config['min_likelihood_path'])\n",
    "my_likelihood.load_state_dict(likelihood_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['dataset_type'] == 'spatio_temporal_data':\n",
    "        data_inputs, data_Y_squeezed, ls_of_ls_train_input, ls_of_ls_test_input, lon_lat_tensor, train_sample_idx_ls, test_sample_idx_ls = prepare_spatio_temp_data(config)\n",
    "\n",
    "n_data4visual = 500\n",
    "inputs_total4visual = Tensor(np.linspace(config['min_input_bound'], config['max_input_bound'], n_data4visual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing via integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_background_information = prepare_common_background_info(my_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_mean, all_pred_var = pred4all_outputs_inputs(my_model=my_model,\n",
    "                                                        my_likelihood=my_likelihood,\n",
    "                                                        data_inputs=data_inputs,\n",
    "                                                        config=config,\n",
    "                                                        common_background_information=common_background_information,\n",
    "                                                        approach='integration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_mean4visual, all_pred_var4visual = pred4all_outputs_inputs(my_model=my_model,\n",
    "                                                        my_likelihood=my_likelihood,\n",
    "                                                        data_inputs=inputs_total4visual,\n",
    "                                                        config=config,\n",
    "                                                        common_background_information=common_background_information,\n",
    "                                                        approach='integration',\n",
    "                                                        not4visual=False,\n",
    "                                                        n_data4visual=n_data4visual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test data RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_predict = all_pred_mean[train_sample_idx_ls]\n",
    "train_rmse = (train_data_predict - data_Y_squeezed[train_sample_idx_ls]).square().mean().sqrt()\n",
    "print('Global Train RMSE via integration', train_rmse)\n",
    "\n",
    "w_test_data_predict = all_pred_mean[test_sample_idx_ls]\n",
    "test_rmse = (w_test_data_predict - data_Y_squeezed[test_sample_idx_ls]).square().mean().sqrt()\n",
    "print('Global Test RMSE via integration', test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test data NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nll = neg_log_likelihood(Target=data_Y_squeezed[train_sample_idx_ls], GaussianMean=all_pred_mean[train_sample_idx_ls], GaussianVar=all_pred_var[train_sample_idx_ls])\n",
    "test_nll = neg_log_likelihood(Target=data_Y_squeezed[test_sample_idx_ls], GaussianMean=all_pred_mean[test_sample_idx_ls], GaussianVar=all_pred_var[test_sample_idx_ls])\n",
    "\n",
    "print('Global Train negative log likelihood via integration:', train_nll)\n",
    "print('Global Test negative log likelihood via integration:', test_nll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over all function index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_list = [] # list of tensors\n",
    "test_rmse_list = []\n",
    "train_nll_list = []\n",
    "test_nll_list = []\n",
    "for output_index in range(config['n_outputs']):\n",
    "    _, _, _, _, _, _, performance_dirct = evaluate_on_single_output(\n",
    "                                                        function_index = output_index,\n",
    "                                                        data_inputs = data_inputs,\n",
    "                                                        data_Y_squeezed = data_Y_squeezed,\n",
    "                                                        ls_of_ls_train_input = ls_of_ls_train_input,\n",
    "                                                        ls_of_ls_test_input = ls_of_ls_test_input,\n",
    "                                                        train_sample_idx_ls = train_sample_idx_ls,\n",
    "                                                        test_sample_idx_ls = test_sample_idx_ls,\n",
    "                                                        all_pred_mean = all_pred_mean,\n",
    "                                                        all_pred_var = all_pred_var,\n",
    "                                                        n_data4visual = n_data4visual,\n",
    "                                                        all_pred_mean4visual = all_pred_mean4visual,\n",
    "                                                        all_pred_var4visual = all_pred_var4visual                                                        \n",
    "                                                        )\n",
    "    train_rmse_list.append(performance_dirct['train_rmse'])\n",
    "    test_rmse_list.append(performance_dirct['test_rmse'])\n",
    "    train_nll_list.append(performance_dirct['train_nll'])\n",
    "    test_nll_list.append(performance_dirct['test_nll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_median_index(lst):\n",
    "    sorted_lst = sorted(lst)\n",
    "    n = len(lst)\n",
    "    \n",
    "    if n % 2 != 0:\n",
    "        median = sorted_lst[n // 2]\n",
    "        return lst.index(median)\n",
    "    else:\n",
    "        mid1 = sorted_lst[n // 2 - 1]\n",
    "        mid2 = sorted_lst[n // 2]\n",
    "        \n",
    "        return lst.index(mid1)  # lst.index(mid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The output index with WORSE test rmse performance: ', test_rmse_list.index(max(test_rmse_list)))\n",
    "print('The output index with WORSE test nll performance: ', test_nll_list.index(max(test_nll_list)))\n",
    "print('------' * 10)\n",
    "print('The output index with MIDDLE test rmse performance:', find_median_index(test_rmse_list))\n",
    "print('The output index with MIDDLE test nll performance:', find_median_index(test_nll_list))\n",
    "print('------' * 10)\n",
    "print('The output index with BEST test rmse performance: ', test_rmse_list.index(min(test_rmse_list)))\n",
    "print('The output index with BEST test nll performance: ', test_nll_list.index(min(test_nll_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_index = 50\n",
    "w_train_input, w_train_target, w_test_input, w_test_target, w_gp_pred_mean, w_gp_pred_std, performance_dirct = evaluate_on_single_output(\n",
    "                                                        function_index = function_index,\n",
    "                                                        data_inputs = data_inputs,\n",
    "                                                        data_Y_squeezed = data_Y_squeezed, \n",
    "                                                        ls_of_ls_train_input = ls_of_ls_train_input,\n",
    "                                                        ls_of_ls_test_input = ls_of_ls_test_input,\n",
    "                                                        train_sample_idx_ls = train_sample_idx_ls,\n",
    "                                                        test_sample_idx_ls = test_sample_idx_ls,\n",
    "                                                        all_pred_mean = all_pred_mean,\n",
    "                                                        all_pred_var = all_pred_var,\n",
    "                                                        n_data4visual = n_data4visual,\n",
    "                                                        all_pred_mean4visual = all_pred_mean4visual,\n",
    "                                                        all_pred_var4visual = all_pred_var4visual                                                        \n",
    ")\n",
    "picture_save_path = f'/Users/jiangxiaoyu/Desktop/All Projects/GPLVM_project_code/experi_results/func_id_{function_index}_numofoutput_{config[\"n_outputs\"]}.png'\n",
    "plot_traindata_testdata_fittedgp(train_X=w_train_input, train_Y=w_train_target, test_X=w_test_input, test_Y=w_test_target, gp_X=inputs_total4visual, gp_pred_mean=w_gp_pred_mean, gp_pred_std=w_gp_pred_std, inducing_points_X=my_model.variational_strategy.inducing_points_input.data, n_inducing_C=config['n_inducing_input'], picture_save_path=picture_save_path) # NOTE: input is C not X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing via mean of latent dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_mean_, all_pred_var_ = pred4all_outputs_inputs(my_model=my_model,\n",
    "                                                        my_likelihood=my_likelihood,\n",
    "                                                        data_inputs=data_inputs,\n",
    "                                                        config=config,\n",
    "                                                        approach='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_mean4visual_, all_pred_var4visual_ = pred4all_outputs_inputs(my_model=my_model,\n",
    "                                                        my_likelihood=my_likelihood,\n",
    "                                                        data_inputs=inputs_total4visual,\n",
    "                                                        config=config,\n",
    "                                                        approach='mean',\n",
    "                                                        not4visual=False,\n",
    "                                                        n_data4visual=n_data4visual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test data RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_predict_ = all_pred_mean_[train_sample_idx_ls]\n",
    "train_rmse_ = (train_data_predict_ - data_Y_squeezed[train_sample_idx_ls]).square().mean().sqrt()\n",
    "print('Global Train RMSE via mean', train_rmse_)\n",
    "\n",
    "w_test_data_predict_ = all_pred_mean_[test_sample_idx_ls]\n",
    "test_rmse_ = (w_test_data_predict_ - data_Y_squeezed[test_sample_idx_ls]).square().mean().sqrt()\n",
    "print('Global Test RMSE via mean', test_rmse_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test data NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nll_ = neg_log_likelihood(Target=data_Y_squeezed[train_sample_idx_ls], GaussianMean=all_pred_mean_[train_sample_idx_ls], GaussianVar=all_pred_var_[train_sample_idx_ls])\n",
    "test_nll_ = neg_log_likelihood(Target=data_Y_squeezed[test_sample_idx_ls], GaussianMean=all_pred_mean_[test_sample_idx_ls], GaussianVar=all_pred_var_[test_sample_idx_ls])\n",
    "\n",
    "print('Global Train negative log likelihood via mean:', train_nll_)\n",
    "print('Global Test negative log likelihood via mean:', test_nll_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over all function index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_list_ = [] # list of tensors\n",
    "test_rmse_list_ = []\n",
    "train_nll_list_ = []\n",
    "test_nll_list_ = []\n",
    "for output_index in range(config['n_outputs']):\n",
    "    _, _, _, _, _, _, performance_dirct = evaluate_on_single_output(\n",
    "                                                        function_index = output_index,\n",
    "                                                        data_inputs = data_inputs,\n",
    "                                                        data_Y_squeezed = data_Y_squeezed,\n",
    "                                                        ls_of_ls_train_input = ls_of_ls_train_input,\n",
    "                                                        ls_of_ls_test_input = ls_of_ls_test_input,\n",
    "                                                        train_sample_idx_ls = train_sample_idx_ls,\n",
    "                                                        test_sample_idx_ls = test_sample_idx_ls,\n",
    "                                                        all_pred_mean = all_pred_mean_,\n",
    "                                                        all_pred_var = all_pred_var_,\n",
    "                                                        n_data4visual = n_data4visual,\n",
    "                                                        all_pred_mean4visual = all_pred_mean4visual_,\n",
    "                                                        all_pred_var4visual = all_pred_var4visual_                                                        \n",
    "                                                        )\n",
    "    train_rmse_list_.append(performance_dirct['train_rmse'])\n",
    "    test_rmse_list_.append(performance_dirct['test_rmse'])\n",
    "    train_nll_list_.append(performance_dirct['train_nll'])\n",
    "    test_nll_list_.append(performance_dirct['test_nll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_median_index(lst):\n",
    "    sorted_lst = sorted(lst)\n",
    "    n = len(lst)\n",
    "    \n",
    "    if n % 2 != 0:\n",
    "        median = sorted_lst[n // 2]\n",
    "        return lst.index(median)\n",
    "    else:\n",
    "        mid1 = sorted_lst[n // 2 - 1]\n",
    "        mid2 = sorted_lst[n // 2]\n",
    "        \n",
    "        return lst.index(mid1)  # lst.index(mid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The output index with WORSE test rmse performance: ', test_rmse_list_.index(max(test_rmse_list_)))\n",
    "print('The output index with WORSE test nll performance: ', test_nll_list_.index(max(test_nll_list_)))\n",
    "print('------' * 10)\n",
    "print('The output index with MIDDLE test rmse performance:', find_median_index(test_rmse_list_))\n",
    "print('The output index with MIDDLE test nll performance:', find_median_index(test_nll_list_))\n",
    "print('------' * 10)\n",
    "print('The output index with BEST test rmse performance: ', test_rmse_list_.index(min(test_rmse_list_)))\n",
    "print('The output index with BEST test nll performance: ', test_nll_list_.index(min(test_nll_list_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_index = 879\n",
    "w_train_input, w_train_target, w_test_input, w_test_target, w_gp_pred_mean, w_gp_pred_std, performance_dirct = evaluate_on_single_output(\n",
    "                                                        function_index = function_index,\n",
    "                                                        data_inputs = data_inputs,\n",
    "                                                        data_Y_squeezed = data_Y_squeezed, \n",
    "                                                        ls_of_ls_train_input = ls_of_ls_train_input,\n",
    "                                                        ls_of_ls_test_input = ls_of_ls_test_input,\n",
    "                                                        train_sample_idx_ls = train_sample_idx_ls,\n",
    "                                                        test_sample_idx_ls = test_sample_idx_ls,\n",
    "                                                        all_pred_mean = all_pred_mean_,\n",
    "                                                        all_pred_var = all_pred_var_,\n",
    "                                                        n_data4visual = n_data4visual,\n",
    "                                                        all_pred_mean4visual = all_pred_mean4visual_,\n",
    "                                                        all_pred_var4visual = all_pred_var4visual_                                                        \n",
    ")\n",
    "picture_save_path = f'/Users/jiangxiaoyu/Desktop/All Projects/GPLVM_project_code/experi_results/func_id_{function_index}_numofoutput_{config[\"n_outputs\"]}.png'\n",
    "plot_traindata_testdata_fittedgp(train_X=w_train_input, train_Y=w_train_target, test_X=w_test_input, test_Y=w_test_target, gp_X=inputs_total4visual, gp_pred_mean=w_gp_pred_mean, gp_pred_std=w_gp_pred_std, inducing_points_X=my_model.variational_strategy.inducing_points_input.data, n_inducing_C=config['n_inducing_input'], picture_save_path=picture_save_path) # NOTE: input is C not X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_time = 1177.4573240280151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPLVM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
